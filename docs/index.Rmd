---
title: "Second BM25 A/B Test Analysis"
subtitle: "First Draft"
author:
- <a href = 'https://meta.wikimedia.org/wiki/User:EBernhardson_(WMF)'>Erik Bernhardson</a> (Engineering)
- <a href = 'https://www.mediawiki.org/wiki/User:DCausse_(WMF)'>David Causse</a> (Engineering & Report)
- <a href = 'https://meta.wikimedia.org/wiki/User:TJones_(WMF)'>Trey Jones</a> (Engineering & Review)
- <a href = 'https://meta.wikimedia.org/wiki/User:MPopov_(WMF)'>Mikhail Popov</a> (Review)
- <a href = 'https://meta.wikimedia.org/wiki/User:DTankersley_(WMF)'>Deb Tankersley</a> (Product Management)
- <a href = 'https://meta.wikimedia.org/wiki/User:CXie_(WMF)'>Chelsy Xie</a> (Analysis & Report)
date: "`r as.character(Sys.Date(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    css: style.css
    fig_caption: yes
    fig_width: 10
    fig_height: 6
    highlight: zenburn
    keep_md: yes
    mathjax: https://tools-static.wmflabs.org/cdnjs/ajax/libs/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML
    md_extensions: +raw_html +markdown_in_html_blocks +tex_math_dollars +fancy_lists +startnum +lists_without_preceding_blankline
    self_contained: no
    theme: flatly
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: no
---
<script language="JavaScript">
$(function() {
  /* Lets the user click on the images to view them in full resolution. */
  $("div.figure img").wrap(function() {
    var link = $('<a/>');
    link.attr('href', $(this).attr('src'));
    link.attr('title', $(this).attr('alt'));
    link.attr('target', '_blank');
    return link;
  });
});
</script>
<p>{ <a href="https://github.com/wikimedia-research/Discovery-Search-2ndTest-BM25_jazhth/blob/master/docs/index.Rmd">RMarkdown Source</a> | <a href="https://github.com/wikimedia-research/Discovery-Search-2ndTest-BM25_jazhth">Analysis Codebase</a> }</p>
```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
options(digits = 3, scipen = 500)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
path <- function(x) {
  if (grepl("docs", getwd(), fixed = TRUE)) {
    return(file.path("..", x))
  } else {
    return(x)
  }
}
```
```{r captions, echo = FALSE}
# Manual figure & table captioning:
library(magrittr)
library(captioner) # install.packages("captioner")
table_caps <- captioner(prefix = "Table")
figure_caps <- captioner(prefix = "Figure")
code_caps <- captioner(prefix = "Snippet")
# Custom caption formatting and printing:
format_caption <- function(caps, name) {
  return({
    sub(caps(name, display = "cite"),
      paste0("**", caps(name, display = "cite"),"**"),
      caps(name, display = "full"), fixed = TRUE) %>%
    sub("  ", " ", ., fixed = TRUE)
  })
}
print_caption <- function(formatted_caption) {
  cat(paste0('<p class = "caption">', formatted_caption, '</p>', collapse = ''))
}
# Add captions:
table_caps(name = "group_counts", caption = "Counts of sessions anonymously tracked and events collected during the second A/B test (Oct 27 - Nov 15).", display = FALSE)
table_caps(name = "group_counts2", caption = "After searchResultPage De-duplication, Counts of sessions anonymously tracked and events collected during the second A/B test (Oct 27 - Nov 15).", display = FALSE)
table_caps(name = "group_counts3", caption = "Counts of visited pages from search sessions anonymously tracked during the second A/B test (Oct 27 - Nov 15).", display = FALSE)
figure_caps("zrr", "Zero results rate is the proportion of searches in which the user received zero results. Broken down by test group.", display = FALSE)
figure_caps("zrr2", "Zero results rate is the proportion of searches in which the user received zero results. Broken down by test group and wiki.", display = FALSE)
figure_caps("paulscore", "Average per-group PaulScore for various values of F (0.1, 0.5, and 0.9) with bootstrapped confidence intervals.", display = FALSE)
figure_caps("paulscore2", "Average per-group PaulScore for various values of F (0.1, 0.5, and 0.9) with bootstrapped confidence intervals. Broken down by test group and wiki.", display = FALSE)
figure_caps("engagement_overall", "Clickthrough rates of test groups.", display = FALSE)
figure_caps("engagement_overall2", "Clickthrough rates broken down by test group and wiki.", display = FALSE)
figure_caps("first_clicked", "First clicked result's position by test group.", display = FALSE)
figure_caps("first_clicked2", "First clicked result's position by test group and wiki.", display = FALSE)
figure_caps("dwell_time", "At time T, at most P% of users still stay on their visited pages. Broken down by test group.", display = FALSE)
figure_caps("dwell_time2", "At time T, at most P% of users still stay on their visited pages. Broken down by test group and wiki.", display = FALSE)
figure_caps("scroll", "Proportion of visited pages with scroll by test group.", display = FALSE)
figure_caps("scroll2", "Proportion of visited pages with scroll by test group and wiki.", display = FALSE)
figure_caps("reform_n", "Proportion of search sessions making N search groups. A search group is a group of searches from the same search session, in which one search is connected with at least another one if they share at least one common word or at least one common result.", display = FALSE)
figure_caps("query_reform_prop", "Proportions of searches where user reformulated their query.", display = FALSE)
figure_caps("query_reform_prop2", "Proportions of searches where user reformulated their query. Broken down by wiki.", display = FALSE)
figure_caps("query_reform_counts", "Proportions of searches with 0, 1, 2, and 3+ query reformulations.", display = FALSE)
figure_caps("query_reform_counts2", "Proportions of searches with 0, 1, 2, and 3+ query reformulations. Broken down by wiki.", display = FALSE)
```

## Executive Summary

In order to assess the efficacy of BM25 in space-less language, Discovery’s Search team has decided to conduct a second A/B test in Chinese, Japanese and Thai Wikipedia. We found that for test group that used per-field query builder with incoming links and pageviews as query-independent factors, we have a much better Zero Result Rate but slightly worse PaulScores, large decrease in clickthrough rate, and fewer users clicked on the first result first, which indicates that we are showing test group users worse results. However, longer dwell time and fewer query reformulation show that test group users may like the results they are getting on some dimension. We recommend deploying BM25 for all wikis but not reindex projects in space-less languages for now.

## Background

To improve the relevancy of search results, Discovery’s Search team decided to try a new document-ranking function called [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25) (BM stands for Best Matching), and ran an [A/B test](https://phabricator.wikimedia.org/T143585) from August 30 to September 10 to assess the efficacy of the proposed switch. The [analysis](https://wikimedia-research.github.io/Discovery-Search-Test-BM25) showed that BM25 ranking with incoming links and pageviews as query-independent factors appears to give users results that are more relevant and that they engage with more. 

However, we then [realized](https://phabricator.wikimedia.org/T147008#2679631) that our analysis chain is sub-optimal for space-less language queries, which will break words on every characters for the plain field. Therefore, we ran a [second A/B test](https://phabricator.wikimedia.org/T147495) for Chinese, Japanese and Thai Wikipedia to test that the new per-field BM25 builder is or is not sufficiently worse on these languages. We are primarily interested in:

* __Zero results rate__, the proportion of searches that yielded zero results (smaller is better)
* __Users' engagement__ with the search results, measured as the clickthrough rate (bigger is better)
* __PaulScore__, a metric of search results' relevancy that relies on the position of the clicked result[s] (bigger is better); see [PaulScore Definition](https://wikimedia-research.github.io/Discovery-Search-Test-BM25/#paulscore_definition) for more details
* __Query reformulation__ -- one way to think about the strength of our search engine is how many times the user reformulates their query; if a user in the test group has to reformulate their query many more times to get the results they are interested in, then maybe the change is for the worse
* __Dwell Time__, the time (seconds) that users stayed on the pages they visited by clicking on the search results (bigger is better)
* __Scroll__ -- if users scroll on the visited page, they are more likely to engage with the contents

```{r install_packages, eval = FALSE}
# Install packages used in the report:
install.packages(c("devtools", "tidyverse", "binom"))
devtools::install_github("hadley/ggplot2")
# ^ development version of ggplot2 includes subtitles
devtools::install_github("wikimedia/wikimedia-discovery-polloi")
# ^ for converting 100000 into 100K via polloi::compress()
```
```{r load_packages}
# Load packages that we will be using in this report:
library(tidyverse) # for ggplot2, dplyr, tidyr, broom, etc.
library(binom) # for Bayesian confidence intervals of proportions
```

```{r paulscore_functions, cache = TRUE}
# PaulScore Calculation
query_score <- function(positions, F) {
   if (length(positions) == 1 || all(is.na(positions))) {
    # no clicks were made
    return(0)
   } else {
     positions <- positions[!is.na(positions)] # when operating on 'events' dataset, searchResultPage events won't have positions
  return(sum(F^positions))
   }
}
# Bootstrapping
bootstrap_mean <- function(x, m, seed = NULL) {
  if (!is.null(seed)) {
    set.seed(seed)
  }
  n <- length(x)
  return(replicate(m, mean(x[sample.int(n, n, replace = TRUE)])))
}
```

## Data

```{r data, cache = TRUE}
# Import events fetched from MySQL
load(path("data/ab-test_bm25.RData"))
events <- events[!duplicated(events$event_id),]
events <- events %>%
  group_by(date, wiki, test_group, session_id, search_id) %>%
  filter("searchResultPage" %in% action) %>%
  ungroup %>% as.data.frame() # remove search_id without SERP asscociated
events$test_group <- factor(
  events$test_group,
  levels = c("bm25:control", "bm25:inclinks_pv"),
  labels = c("Control Group (tf–idf)", "Using per-field query builder with incoming links and pageviews as QIFs"))
cirrus <- readr::read_tsv(path("data/ab-test_bm25_cirrus-results.tsv.gz"), col_types = "cccc")
cirrus <- cirrus[!duplicated(cirrus),]
events <- left_join(events, cirrus, by = c("event_id", "page_id", "cirrus_id"))
rm(cirrus)
```

For Chinese Wikipedia (zhwiki) and Japanese Wikipedia (jawiki), users had a 1 in 16 chance of being selected for search satisfaction tracking according to our [TestSearchSatisfaction2 #15922352](https://meta.wikimedia.org/w/index.php?title=Schema:TestSearchSatisfaction2&id=15922352) schema. Those users who were randomly selected to have their sessions anonymously tracked then had a 12 in 13 chance of being selected for the BM25 test. For Thai Wikipedia (thwiki), users had a 1 in 5 chance of being selected for search satisfaction tracking and then had a 38 in 39 chance of being selected for the BM25 test. The sampled sessions were evenly put into control group (tf-idf) and test group (Using per-field query builder with incoming links and pageviews as QIFs); see the [first BM25 test report](https://wikimedia-research.github.io/Discovery-Search-Test-BM25/#data) for more details. The test was deployed on October 27th and ran for a week for zhwiki and jawiki; for thwiki, we ran the test from October 27 to November 15. 

The full-text (as opposed to auto-complete) searching event logging data was extracted from the database using this [script](https://github.com/wikimedia-research/Discovery-Search-2ndTest-BM25_jazhth/blob/master/data.R). We collected a total of `r polloi::compress(nrow(events), 1)` events from `r polloi::compress(length(unique(events$search_id)), 1)` unique sessions. See `r table_caps("group_counts", display = "cite")` for counts broken down by wiki and test group.

```{r summary, results = "asis", dependson = "data"}
events_summary <- events %>%
  group_by(wiki, `Test group` = test_group) %>%
  summarize(`Search sessions` = length(unique(search_id)), `Events recorded` = n()) %>% ungroup %>%
  {
    rbind(., tibble(
      `wiki` = "All Wikis",
      `Test group` = "Total",
      `Search sessions` = sum(.$`Search sessions`),
      `Events recorded` = sum(.$`Events recorded`)
    ))
  } %>%
  mutate(`Search sessions` = prettyNum(`Search sessions`, big.mark = ","),
         `Events recorded` = prettyNum(`Events recorded`, big.mark = ","))
knitr::kable(events_summary, format = "markdown", align = c("l", "l", "r", "r"))
```
```{r summary_caption, results = "asis", echo = FALSE}
print_caption(format_caption(table_caps, "group_counts"))
```

An issue we noticed with the event logging is that when the user goes to the next page of search results or clicks the Back button after visiting a search result, a new page ID is generated for the search results page. The page ID is how we connect click events to search result page events. There is currently a Phabricator ticket ([T146337](https://phabricator.wikimedia.org/T146337)) for addressing these issues. For this analysis, we de-duplicated by connecting search engine results page (searchResultPage) events that have the exact same search query, and then connected click events together based on the searchResultPage connectivity.

```{r searchResultPage_deduplication, dependson = "data", cache = TRUE}
temp <- events %>%
  filter(action == "searchResultPage") %>%
  group_by(session_id, search_id, query) %>%
  mutate(new_page_id = min(page_id)) %>%
  ungroup %>%
  select(c(page_id, new_page_id)) %>%
  distinct
events <- left_join(events, temp, by = "page_id"); rm(temp)
events$new_page_id[is.na(events$new_page_id)] <- events$page_id[is.na(events$new_page_id)] 
temp <- events %>%
  filter(action == "searchResultPage") %>%
  arrange(new_page_id, ts) %>%
  mutate(dupe = duplicated(new_page_id, fromLast = FALSE)) %>%
  select(c(event_id, dupe))
events <- left_join(events, temp, by = "event_id"); rm(temp)
events$dupe[events$action != "searchResultPage"] <- FALSE
events <- events[!events$dupe & !is.na(events$new_page_id), ] %>%
  select(-c(page_id, dupe)) %>%
  rename(page_id = new_page_id) %>%
  arrange(date, session_id, search_id, page_id, desc(action), ts)
```
```{r aggregation, dependson = c("searchResultPage_deduplication", "paulscore_functions"), cache = TRUE}
# Summarize on a page-by-page basis for each SERP:
searches <- events %>%
  group_by(wiki, `test group` = test_group, session_id, search_id, page_id) %>%
  filter("searchResultPage" %in% action) %>% # filter out searches where we have clicks but not searchResultPage events
  summarize(ts = ts[1], query = query[1],
            results = ifelse(n_results_returned[1] > 0, "some", "zero"),
            clickthrough = "click" %in% action,
            `no. results clicked` = length(unique(position_clicked))-1,
            `first clicked result's position` = ifelse(clickthrough, position_clicked[2], NA),
            `result page IDs` = paste(unique(result_pids[!is.na(result_pids)]), collapse=','),
            `Query score (F=0.1)` = query_score(position_clicked, 0.1),
            `Query score (F=0.5)` = query_score(position_clicked, 0.5),
            `Query score (F=0.9)` = query_score(position_clicked, 0.9)) %>%
  arrange(ts)
searches$`result page IDs`[searches$`result page IDs`==""] <- NA
```
After de-duplicating, we collapsed `r polloi::compress(nrow(events), 1)` (searchResultPage and click) events into `r polloi::compress(nrow(searches), 1)` searches. See `r table_caps("group_counts2", display = "cite")` for counts broken down by wiki and test group.

```{r summary2, results = "asis", dependson = c("searchResultPage_deduplication","aggregation")}
events_summary2 <- events %>%
  group_by(wiki, `Test group` = test_group) %>%
  summarize(`Search sessions` = length(unique(search_id)), `Events recorded` = n()) %>% ungroup %>%
  {
    rbind(., tibble(
      `wiki` = "All Wikis",
      `Test group` = "Total",
      `Search sessions` = sum(.$`Search sessions`),
      `Events recorded` = sum(.$`Events recorded`)
    ))
  } %>%
  mutate(`Search sessions` = prettyNum(`Search sessions`, big.mark = ","),
         `Events recorded` = prettyNum(`Events recorded`, big.mark = ","))
searches_summary <- searches %>%
  group_by(wiki, `Test group` = `test group`) %>%
  summarize(`Search sessions` = length(unique(search_id)), `Searches recorded` = n()) %>% ungroup %>%
  {
    rbind(., tibble(
      `wiki` = "All Wikis",
      `Test group` = "Total",
      `Search sessions` = sum(.$`Search sessions`),
      `Searches recorded` = sum(.$`Searches recorded`)
    ))
  } %>%
  mutate(`Search sessions` = prettyNum(`Search sessions`, big.mark = ","),
         `Searches recorded` = prettyNum(`Searches recorded`, big.mark = ","))
knitr::kable(inner_join(searches_summary, events_summary2, by=c("wiki", "Test group", "Search sessions")), 
             format = "markdown", align = c("l", "l", "r", "r", "r"))
```
```{r summary_caption2, results = "asis", echo = FALSE}
print_caption(format_caption(table_caps, "group_counts2"))
```

There are `r polloi::compress(length(unique(events$page_id[events$action=="visitPage"])), 1)` visitPage events (When the user clicks a link in the results a visitPage event is created). See `r table_caps("group_counts3", display = "cite")` for counts broken down by wiki and test group.

```{r aggregation_visits, dependson = "searchResultPage_deduplication", cache = TRUE}
# Summarize on a page-by-page basis for each visitPage:
clickedResults <- events %>%
  group_by(wiki, `test group` = test_group, session_id, search_id, page_id) %>%
  filter("visitPage" %in% action) %>% #only checkin and visitPage action
  summarize(ts = ts[1], 
            dwell_time=ifelse("checkin"%in% action, max(checkin, na.rm=T), 0),
            scroll=sum(scroll)>0) %>%
  arrange(ts)
clickedResults$dwell_time[is.na(clickedResults$dwell_time)] <- 0
```
```{r summary3, results = "asis", dependson = "aggregation_visits"}
clickedResults_summary <- clickedResults %>%
  group_by(wiki, `Test group` = `test group`) %>%
  summarize(`Visited pages` = length(unique(page_id))) %>% ungroup %>%
  {
    rbind(., tibble(
      `wiki` = "All Wikis",
      `Test group` = "Total",
      `Visited pages` = sum(.$`Visited pages`)
    ))
  } %>%
  mutate(`Visited pages` = prettyNum(`Visited pages`, big.mark = ","))
knitr::kable(clickedResults_summary, format = "markdown", align = c("l", "l", "r", "r"))
```
```{r summary_caption3, results = "asis", echo = FALSE}
print_caption(format_caption(table_caps, "group_counts3"))
```

## Results

### Zero Results Rate

In `r figure_caps("zrr", display = "cite")`, we see that the test group that used BM25 with incoming links and pageviews as query-independent factors had a significantly lower ZRR, but perhaps at the cost of relevance and engagement with the results. `r figure_caps("zrr2", display = "cite")` shows that zhwiki had the largest ZRR difference between control and test group.

```{r zrr, dependson = "query_clustering", cache = TRUE}
zrr_pages <- searches %>%
  group_by(`test group`, results) %>%
  tally %>%
  spread(results, n) %>%
  mutate(`zero results rate` = zero/(some + zero)) %>%
  ungroup
zrr_pages <- cbind(zrr_pages, as.data.frame(binom:::binom.bayes(zrr_pages$zero, n = zrr_pages$some + zrr_pages$zero)[, c("mean", "lower", "upper")]))
```
```{r zrr_caption, echo = FALSE}
zrr_cap <- format_caption(figure_caps, "zrr")
```
```{r zrr_eda, fig.cap = zrr_cap, dependson = "zrr"}
zrr_pages %>%
  ggplot(aes(x = `test group`, y = `mean`, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper)) +
  scale_x_discrete(limits = rev(levels(events$test_group))) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_color_brewer("Test Group", palette = "Set1", guide = FALSE) +
  labs(x = NULL, y = "Zero Results Rate",
       title = "Proportion of searches that did not yield any results, by test group",
       subtitle = "With 95% credible intervals.") +
  geom_text(aes(label = sprintf("%.2f%%", 100 * `zero results rate`),
                vjust = "bottom", hjust = "center"), nudge_x = 0.1) 
```
```{r zrr_caption2, echo = FALSE}
zrr_cap2 <- format_caption(figure_caps, "zrr2")
```
```{r zrr_eda2, fig.cap = zrr_cap2, dependson = "zrr"}
zrr_pages <- searches %>%
  group_by(wiki, `test group`, results) %>%
  tally %>%
  spread(results, n) %>%
  mutate(`zero results rate` = zero/(some + zero)) %>%
  ungroup
zrr_pages <- cbind(zrr_pages, as.data.frame(binom:::binom.bayes(zrr_pages$zero, n = zrr_pages$some + zrr_pages$zero)[, c("mean", "lower", "upper")]))
zrr_pages %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  scale_y_continuous(labels = scales::percent_format(), expand = c(0.01, 0.01)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  labs(x = NULL, y = "Zero Results Rate",
       title = "Proportion of searches that did not yield any results, by test group and wiki",
       subtitle = "With 95% credible intervals.") +
  geom_text(aes(label = sprintf("%.2f%%", 100 * `zero results rate`),
                y = upper + 0.0025, vjust = "bottom"), position = position_dodge(width = 1)) +
  facet_wrap(~ wiki, ncol = 3) +
  theme(legend.position = "bottom")
```

### PaulScore

In `r figure_caps("paulscore", display = "cite")`, we see that the test group had slightly lower PaulScores, which indicates that the results were less relevant. The difference is not significant when F = 0.9. `r figure_caps("paulscore2", display = "cite")` shows that zhwiki had the largest PaulScore differences between control and test group.

```{r paulscores, dependson = "query_clustering", cache = TRUE}
set.seed(777)
paulscores <- searches %>%
  ungroup %>%
  filter(clickthrough==TRUE) %>% #???
  select(c(`test group`, `Query score (F=0.1)`, `Query score (F=0.5)`, `Query score (F=0.9)`)) %>%
  gather(`F value`, `Query score`, -`test group`) %>%
  mutate(`F value` = sub("^Query score \\(F=(0\\.[159])\\)$", "F = \\1", `F value`)) %>%
  group_by(`test group`, `F value`) %>%
  summarize(
    PaulScore = mean(`Query score`),
    Interval = paste0(quantile(bootstrap_mean(`Query score`, 1000), c(0.025, 0.975)), collapse = ",")
  ) %>%
  extract(Interval, into = c("Lower", "Upper"), regex = "(.*),(.*)", convert = TRUE)
```

```{r paulscores_caption, echo = FALSE}
paulscore_cap <- format_caption(figure_caps, "paulscore")
```
```{r paulscores_eda, fig.cap = paulscore_cap, dependson = "paulscores"}
paulscores %>%
  ggplot(aes(x = `F value`, y = PaulScore, color = `test group`)) +
  geom_pointrange(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.7)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  #scale_y_continuous(limits = c(0.2, 0.35)) +
  labs(x = NULL, y = "PaulScore(F)",
       title = "PaulScore(F) by test group and value of F",
       subtitle = "With bootstrapped 95% confidence intervals.") +
  geom_text(aes(label = sprintf("%.3f", PaulScore), y = Upper + 0.01, vjust = "bottom"),
            position = position_dodge(width = 0.7)) +
  theme(legend.position = "bottom") 
```
```{r paulscores_caption2, echo = FALSE}
paulscore_cap2 <- format_caption(figure_caps, "paulscore2")
```
```{r paulscores_eda2, fig.cap = paulscore_cap2, dependson = "paulscores"}
set.seed(777)
paulscores <- searches %>%
  ungroup %>%
  filter(clickthrough==TRUE) %>% 
  select(c(wiki, `test group`, `Query score (F=0.1)`, `Query score (F=0.5)`, `Query score (F=0.9)`)) %>%
  gather(`F value`, `Query score`, -c(`test group`, wiki)) %>%
  mutate(`F value` = sub("^Query score \\(F=(0\\.[159])\\)$", "F = \\1", `F value`)) %>%
  group_by(wiki, `test group`, `F value`) %>%
  summarize(
    PaulScore = mean(`Query score`),
    Interval = paste0(quantile(bootstrap_mean(`Query score`, 1000), c(0.025, 0.975)), collapse = ",")
  ) %>%
  extract(Interval, into = c("Lower", "Upper"), regex = "(.*),(.*)", convert = TRUE)
paulscores %>%
  ggplot(aes(x = `F value`, y = PaulScore, color = `test group`)) +
  geom_pointrange(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.7)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  #scale_y_continuous(limits = c(0.2, 0.35)) +
  labs(x = NULL, y = "PaulScore(F)",
       title = "PaulScore(F) by wiki, test group and value of F",
       subtitle = "With bootstrapped 95% confidence intervals.") +
  geom_text(aes(label = sprintf("%.3f", PaulScore), y = Upper + 0.01, vjust = "bottom"),
            position = position_dodge(width = 0.7)) +
  facet_wrap(~ wiki, ncol = 3) +
  theme(legend.position = "bottom") 
```

### Engagement

In `r figure_caps("engagement_overall", display = "cite")`, we see that the test group had a significantly lower clickthrough rate, which means users are less engaged with their search results. Again, zhwiki shows the largest discrepancy between control and test group in `r figure_caps("engagement_overall2", display = "cite")`.

```{r engagement_overall, dependson = "query_reformulations", cache = TRUE}
engagement_overall <- searches %>%
  filter(results=="some") %>% #???
  group_by(`test group`) %>%
  summarize(clickthroughs = sum(clickthrough > 0),
            searches = n(), ctr = clickthroughs/searches) %>%
  ungroup
engagement_overall <- cbind(
  engagement_overall,
  as.data.frame(
    binom:::binom.bayes(
      engagement_overall$clickthroughs,
      n = engagement_overall$searches)[, c("mean", "lower", "upper")]
  )
)
```
```{r engagement_overall_caption, echo = FALSE}
engagement_overall_cap <- format_caption(figure_caps, "engagement_overall")
```
```{r engagement_overall_eda, fig.cap = engagement_overall_cap, dependson = "engagement_overall"}
engagement_overall %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  scale_y_continuous(labels = scales::percent_format(), expand = c(0.01, 0.01)) +
  labs(x = NULL, y = "Clickthrough rate",
       title = "Engagement with search results by test group") +
  geom_text(aes(label = sprintf("%.1f%%", 100 * ctr), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  theme(legend.position = "bottom")
```
```{r engagement_overall_caption2, echo = FALSE}
engagement_overall_cap2 <- format_caption(figure_caps, "engagement_overall2")
```
```{r engagement_overall_eda2, fig.cap = engagement_overall_cap2, dependson = "engagement_overall"}
engagement_overall <- searches %>%
  filter(results=="some") %>% 
  group_by(wiki, `test group`) %>%
  summarize(clickthroughs = sum(clickthrough > 0),
            searches = n(), ctr = clickthroughs/searches) %>%
  ungroup
engagement_overall <- cbind(
  engagement_overall,
  as.data.frame(
    binom:::binom.bayes(
      engagement_overall$clickthroughs,
      n = engagement_overall$searches)[, c("mean", "lower", "upper")]
  )
)
engagement_overall %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  scale_y_continuous(labels = scales::percent_format(), expand = c(0.01, 0.01)) +
  labs(x = NULL, y = "Clickthrough rate",
       title = "Engagement with search results by test group and wiki") +
  geom_text(aes(label = sprintf("%.1f%%", 100 * ctr), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  facet_wrap(~ wiki, ncol = 3) +
  theme(legend.position = "bottom")
```

### First Clicked Result's Position

In `r figure_caps("first_clicked", display = "cite")`, we see that test group users were less likely to click on the first search result first than the control group. `r figure_caps("first_clicked2", display = "cite")` shows that only zhwiki users first clicked on the first result at a significantly lower rate, which indicates that the results were less relevant.

```{r first_clicked_position, dependson = "query_reformulations", cache = TRUE}
safe_ordinals <- function(x) {
  return(vapply(x, toOrdinal::toOrdinal, ""))
}
first_clicked <- searches %>%
  filter(results == "some" & clickthrough & !is.na(`first clicked result's position`)) %>%
  mutate(`first clicked result's position` = ifelse(`first clicked result's position` < 4, safe_ordinals(`first clicked result's position` + 1), "5th or higher")) %>%
  group_by(`test group`, `first clicked result's position`) %>%
  tally %>%
  mutate(total = sum(n), prop = n/total) %>%
  ungroup
set.seed(0)
temp <- as.data.frame(binom:::binom.bayes(first_clicked$n, n = first_clicked$total, tol = .Machine$double.eps^0.1)[, c("mean", "lower", "upper")])
first_clicked <- cbind(first_clicked, temp); rm(temp)
```
```{r first_clicked_position_caption, echo = FALSE}
first_clicked_cap <- format_caption(figure_caps, "first_clicked")
```
```{r first_clicked_position_eda, fig.cap = first_clicked_cap, dependson = "first_clicked_position"}
first_clicked %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  geom_text(aes(label = sprintf("%.1f", 100 * prop), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  scale_y_continuous(labels = scales::percent_format(),
                     expand = c(0, 0.005), breaks = seq(0, 1, 0.01)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  facet_wrap(~ `first clicked result's position`, scale = "free_y", nrow = 1) +
  labs(x = NULL, y = "Proportion of searches",
       title = "Position of the first clicked result",
       subtitle = "With 95% credible intervals") +
  theme(legend.position = "bottom",
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        strip.background = element_rect(fill = "gray90"),
        panel.border = element_rect(color = "gray30", fill = NA))
```
```{r first_clicked_position_caption2, echo = FALSE}
first_clicked_cap2 <- format_caption(figure_caps, "first_clicked2")
```
```{r first_clicked_position_eda2, fig.cap = first_clicked_cap2, dependson = "first_clicked_position", fig.height=10}
first_clicked <- searches %>%
  filter(results == "some" & clickthrough & !is.na(`first clicked result's position`)) %>%
  mutate(`first clicked result's position` = ifelse(`first clicked result's position` < 4, safe_ordinals(`first clicked result's position` + 1), "5th or higher")) %>%
  group_by(wiki, `test group`, `first clicked result's position`) %>%
  tally %>%
  mutate(total = sum(n), prop = n/total) %>%
  ungroup
set.seed(0)
temp <- as.data.frame(binom:::binom.bayes(first_clicked$n, n = first_clicked$total, tol = .Machine$double.eps^0.1)[, c("mean", "lower", "upper")])
first_clicked <- cbind(first_clicked, temp); rm(temp)
first_clicked %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  geom_text(aes(label = sprintf("%.1f", 100 * prop), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  scale_y_continuous(labels = scales::percent_format(),
                     expand = c(0, 0.005), breaks = seq(0, 1, 0.01)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  facet_wrap(~ wiki+`first clicked result's position`, scale = "free_y", ncol=5, nrow = 3) +
  labs(x = NULL, y = "Proportion of searches",
       title = "Position of the first clicked result",
       subtitle = "With 95% credible intervals") +
  theme(legend.position = "bottom",
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        strip.background = element_rect(fill = "gray90"),
        panel.border = element_rect(color = "gray30", fill = NA))
```

### Dwell Time per Visited Page

Figures `r figure_caps("dwell_time", display = "num")` and `r figure_caps("dwell_time2", display = "num")` show the survival curve for each test group and wiki. Except zhwiki, users are more likely to stay longer on visited pages, which implies the results in test group are more relevant for jawiki and thwiki.

```{r dwell_time_caption, echo = FALSE}
dwell_time_cap <- format_caption(figure_caps, "dwell_time")
```
```{r dwell_time_eda, fig.cap = dwell_time_cap, dependson = "aggregation_visits"}
clickedResults %>%
  split(.$`test group`) %>% 
  map_df(function(df) {
    seconds <- c(0, 10, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210, 240, 300, 360, 420)
    seshs <- as.data.frame(do.call(cbind, lapply(seconds, function(second) {
      return(sum(df$dwell_time >= second))
    })))
    names(seshs) <- seconds
    return(cbind(`test group` = head(df$`test group`, 1), n = seshs$`0`, seshs, `450`=seshs$`420`))
  }) %>%
  gather(seconds, visits, -c(`test group`, n)) %>%
  mutate(seconds = as.numeric(seconds)) %>%
  group_by(`test group`, seconds) %>%
  mutate(proportion = visits/n) %>%
  ungroup() %>%
  ggplot(aes(group=`test group`, color=`test group`)) +
  geom_step(aes(x = seconds, y = proportion), direction = "hv") +
  scale_x_continuous(name = "T (Dwell Time in seconds)", breaks=c(0, 10, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210, 240, 300, 360, 420))+ 
  scale_y_continuous("Proportion of visits longer than T (P%)", labels = scales::percent_format(),
                     breaks = seq(0, 1, 0.1)) +
  theme(legend.position = "bottom")
```
```{r dwell_time_caption2, echo = FALSE}
dwell_time_cap2 <- format_caption(figure_caps, "dwell_time2")
```
```{r dwell_time_eda_wiki, fig.cap = dwell_time_cap2, dependson = "aggregation_visits", fig.height=10}
clickedResults %>%
  split(list(.$wiki, .$`test group`)) %>% 
  map_df(function(df) {
    seconds <- c(0, 10, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210, 240, 300, 360, 420)
    seshs <- as.data.frame(do.call(cbind, lapply(seconds, function(second) {
      return(sum(df$dwell_time >= second))
    })))
    names(seshs) <- seconds
    return(cbind(wiki=head(df$wiki, 1), `test group` = head(df$`test group`, 1), n = seshs$`0`, seshs, `450`=seshs$`420`))
  }) %>%
  gather(seconds, visits, -c(wiki, `test group`, n)) %>%
  mutate(seconds = as.numeric(seconds)) %>%
  group_by(wiki, `test group`, seconds) %>%
  mutate(proportion = visits/n) %>%
  ungroup() %>%
  ggplot(aes(group=`test group`, color=`test group`)) +
  geom_step(aes(x = seconds, y = proportion), direction = "hv") +
  scale_x_continuous(name = "T (Dwell Time in seconds)", breaks=c(0, 10, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210, 240, 300, 360, 420))+ 
  scale_y_continuous("Proportion of visits longer than T (P%)", labels = scales::percent_format(),
                     breaks = seq(0, 1, 0.1)) +
  theme(legend.position = "bottom") +
  facet_wrap(~ wiki, ncol=1, nrow =3)
```

### Scroll

In Figures `r figure_caps("scroll", display = "num")` and `r figure_caps("scroll2", display = "num")`, we can see that users in the test group are more likely to scroll on the visited pages, but the differences are not statistically significant.

```{r scroll_caption, echo = FALSE}
scroll_cap <- format_caption(figure_caps, "scroll")
```
```{r scroll_eda, fig.cap = scroll_cap, dependson = "aggregation_visits"}
scroll_overall <- clickedResults %>%
  group_by(`test group`) %>%
  summarize(scrolls=sum(scroll), visits=n(), proportion = sum(scroll)/n()) %>%
  ungroup
scroll_overall <- cbind(
  scroll_overall,
  as.data.frame(
    binom:::binom.bayes(
      scroll_overall$scrolls,
      n = scroll_overall$visits)[, c("mean", "lower", "upper")]
  )
)
scroll_overall %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  scale_y_continuous(labels = scales::percent_format(), expand = c(0.01, 0.01)) +
  labs(x = NULL, y = "Proportion of visits",
       title = "Proportion of visits with scroll by test group") +
  geom_text(aes(label = sprintf("%.1f%%", 100 * proportion), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  theme(legend.position = "bottom")
```
```{r scroll_caption2, echo = FALSE}
scroll_cap2 <- format_caption(figure_caps, "scroll2")
```
```{r scroll_eda_wiki, fig.cap = scroll_cap2, dependson = "aggregation_visits"}
scroll_overall <- clickedResults %>%
  group_by(wiki, `test group`) %>%
  summarize(scrolls=sum(scroll), visits=n(), proportion = sum(scroll)/n()) %>%
  ungroup
scroll_overall <- cbind(
  scroll_overall,
  as.data.frame(
    binom:::binom.bayes(
      scroll_overall$scrolls,
      n = scroll_overall$visits)[, c("mean", "lower", "upper")]
  )
)
scroll_overall %>%
  ggplot(aes(x = 1, y = mean, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  scale_y_continuous(labels = scales::percent_format(), expand = c(0.01, 0.01)) +
  labs(x = NULL, y = "Proportion of visits",
       title = "Proportion of visits with scroll by test group and wiki") +
  geom_text(aes(label = sprintf("%.1f%%", 100 * proportion), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  facet_wrap(~ wiki, ncol = 3) +
  theme(legend.position = "bottom")
```

### Query Reformulation

First, we tokenized queries from zhwiki, jawiki and thwiki with [jieba](https://github.com/fxsjy/jieba), [tinysegmenter](https://pypi.python.org/pypi/tinysegmenter) and [elasticsearch termvectors api](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-termvectors.html) separately. Then we filter out [stop words](https://github.com/6/stopwords-json).

```{r tokenization, cache = TRUE}
# See tokenize.R for more details
library(jiebaR)
library(ropencc)

#thwiki
load("../data/tokens_th.RData")
tokens_th <- output; rm(output)
stopword_th <- jsonlite::fromJSON("../resource/th.json")
tokens_th <- filter_segment(tokens_th,stopword_th)

#zhwiki
queries_zh <- searches[searches$wiki=="zhwiki", c("page_id","query")]
queries_zh$query <- gsub("[[:punct:]]", " ", queries_zh$query)
stopword_zh <- jsonlite::fromJSON("../resource/zh.json")
ccst = converter(S2T)
stopword_zh <- union(ccst[stopword_zh], stopword_zh)
mixseg = worker(bylines = TRUE)
tokens_zh <- mixseg[queries_zh$query]
tokens_zh <- filter_segment(tokens_zh,stopword_zh)
names(tokens_zh) <- queries_zh$page_id

#jawiki
tokens_ja <- jsonlite::fromJSON("../data/tokens_ja.json")
stopword_ja <- jsonlite::fromJSON("../resource/ja.json")
tokens_ja <- filter_segment(tokens_ja,stopword_ja)
tokens_ja <- lapply(tokens_ja, function(x) gsub(" +","",x)) # strip space before/after string
```

We consider two queries as a reformulation if 1) they are from the same search session and share at least one result, or 2) they are from the same search session and share at least one word.

```{r reformulation, dependson="tokenization", cache = TRUE}
library(igraph)
all_tokens <- c(tokens_ja, tokens_zh, tokens_th)

overlapping_results <- function(x) {
  if (all(is.na(x))) {
    return(diag(length(x)))
  }
  input <- strsplit(stringr::str_replace_all(x, "[\\[\\]]", ""), ",")
  output <- vapply(input, function(y) {
    temp <- vapply(input, function(z) { length(intersect(z, y)) }, 0L)
    temp[is.na(x)] <- 0L
    return(temp)
  }, rep(0L, length(input)))
  diag(output) <- 1L
  return(output)
}

reformulation <- function(result_pids, page_ids, all_tokens) {
  if(length(page_ids)==1){
    return(data.frame(n_search=1, n_reformulate="0"))
  }
  # result overlap
  overlaps_res <- overlapping_results(result_pids)
  # tokens overlap
  this_tokens <- all_tokens[page_ids]
  overlaps_token <- vapply(this_tokens, function(y) {
    temp <- vapply(this_tokens, function(z) { length(intersect(z, y)) }, 0L)
    temp[is.na(this_tokens)] <- 0L
    return(temp)
  }, rep(0L, length(this_tokens)))
  diag(overlaps_token) <- 1L
  
  overlaps_all <- (overlaps_res + overlaps_token) > 0
  diag(overlaps_all) <- 0L
  graph_object <- graph_from_adjacency_matrix(overlaps_all, mode = c("undirected"), diag = F)
  csize <- clusters(graph_object)$csize
  return(data.frame(n_search=length(csize), n_reformulate=ifelse(length(csize)>1,paste(csize-1, collapse=',' ), as.character(csize-1))))
}

reform_times <- searches %>% 
  group_by(wiki, `test group`, session_id, search_id) %>% 
  do(reformulation(.$`result page IDs`, .$page_id, all_tokens))
```

We grouped connected searches together using the rules above, then we have 51354 total search groups.

```{r reform_n_search_group_caption, echo = FALSE}
reform_n_search_group_cap <- format_caption(figure_caps, "reform_n")
```
```{r reform_n_search_group, fig.cap = reform_n_search_group_cap, dependson = "reformulation"}
reform_times %>% ungroup %>%
  mutate(n_search=ifelse(n_search>=10,"10+",n_search)) %>%
  group_by(n_search) %>%
  summarise(n_session=n()) %>%
  mutate(prop=n_session/sum(n_session)) %>%
  ggplot(aes(x = n_search, y = prop)) +
  geom_bar(stat = "identity") +
  scale_y_continuous("Proportion of search sessions", labels = scales::percent_format()) +
  scale_x_discrete("Number of Search Groups", limits = c(1:9, "10+")) +
  geom_text(aes(label = sprintf("%.1f%%", 100*prop)), nudge_y = 0.025) +
  ggthemes::theme_tufte(base_family = "Gill Sans", base_size = 14) +
  ggtitle("Proportion of search sessions making N search groups")
```

In `r figure_caps("query_reform_prop", display = "cite")` and `r figure_caps("query_reform_counts", display = "cite")`, we can see that test group users are less likely to reformulate their queries. `r figure_caps("query_reform_prop2", display = "cite")` and `r figure_caps("query_reform_counts2", display = "cite")` show that zhwiki had the largest discrepancy between control and test group.

```{r query_reformulations_prop_caption, echo = FALSE}
query_reform_prop_cap <- format_caption(figure_caps, "query_reform_prop")
```
```{r reform_eda1, fig.cap = query_reform_prop_cap, dependson = "reformulation"}
reformulation_counts <- reform_times %>%
  group_by(`test group`) %>%
  summarize(`searches with query reformulations` = sum(as.numeric(unlist(lapply(n_reformulate, function(x) strsplit(x, ",")))) > 0),
            searches = sum(n_search),
            proportion = `searches with query reformulations`/searches) %>%
  ungroup
reformulation_counts <- cbind(
  reformulation_counts,
  as.data.frame(
    binom:::binom.bayes(
      reformulation_counts$`searches with query reformulations`,
      n = reformulation_counts$searches,
      tol = .Machine$double.eps^0.1)[, c("mean", "lower", "upper")]
  )
)
reformulation_counts %>%
  ggplot(aes(x = `test group`, y = `mean`, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper)) +
  scale_x_discrete(limits = rev(levels(events$test_group))) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_color_brewer("Test Group", palette = "Set1", guide = FALSE) +
  labs(x = NULL, y = "% of searches with query reformulations",
       title = "Searches with reformulated queries by test group",
       subtitle = "Queries were grouped when they shared common results or common key words") +
  geom_text(aes(label = sprintf("%.2f%%", 100 * proportion),
                vjust = "bottom", hjust = "center"), nudge_x = 0.1)
```
```{r query_reformulations_prop_caption2, echo = FALSE}
query_reform_prop_cap2 <- format_caption(figure_caps, "query_reform_prop2")
```
```{r reform_eda1_wiki, fig.cap = query_reform_prop_cap2, dependson = "reformulation"}
reformulation_counts <- reform_times %>%
  group_by(wiki, `test group`) %>%
  summarize(`searches with query reformulations` = sum(as.numeric(unlist(lapply(n_reformulate, function(x) strsplit(x, ",")))) > 0),
            searches = sum(n_search),
            proportion = `searches with query reformulations`/searches) %>%
  ungroup
reformulation_counts <- cbind(
  reformulation_counts,
  as.data.frame(
    binom:::binom.bayes(
      reformulation_counts$`searches with query reformulations`,
      n = reformulation_counts$searches)[, c("mean", "lower", "upper")]
  )
)
reformulation_counts %>%
  ggplot(aes(x = 1, y = `mean`, color = `test group`)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 1)) +
  scale_y_continuous(labels = scales::percent_format(), expand = c(0.01, 0.01)) +
  scale_color_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  labs(x = NULL, y = "% of searches with query reformulations",
       title = "Searches with reformulated queries by test group and wiki",
       subtitle = "Queries were grouped when they shared common results or common key words") +
  geom_text(aes(label = sprintf("%.1f%%", 100 * proportion), y = upper + 0.0025, vjust = "bottom"),
            position = position_dodge(width = 1)) +
  theme(legend.position = "bottom")+
  facet_wrap(~ wiki, ncol = 3)
```

```{r query_reformulations_counts_caption, echo = FALSE}
query_reform_counts_cap <- format_caption(figure_caps, "query_reform_counts")
```
```{r reform_eda2, fig.cap = query_reform_counts_cap, dependson = "reformulation", cache = TRUE}
count_reformulation <- function(n_reformulate){
  temp <- as.numeric(unlist(lapply(n_reformulate, function(x) strsplit(x, ","))))
  temp <- ifelse(temp>=3, "3+", temp)
  output <- as.data.frame(table(temp))
  output$proportion <- output$Freq/sum(output$Freq)
  colnames(output)[1] <- "query reformulations"
  return(output)
}
reform_times %>%
  group_by(`test group`) %>%
  do(count_reformulation(.$n_reformulate)) %>%
  ggplot(aes(x = `query reformulations`, y = proportion, fill = `test group`)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  geom_text(aes(label = sprintf("%.1f%%", 100 * proportion), vjust = "bottom"),
            position = position_dodge(width = 1)) +
  labs(y = "Proportion of searches", x = "Approximate number of query reformulations per grouped search",
       title = "Number of query reformulations by test group",
       subtitle = "Queries were grouped when they shared common results or common key words") +
  theme(legend.position = "bottom")
```
```{r query_reformulations_counts_caption2, echo = FALSE}
query_reform_counts_cap2 <- format_caption(figure_caps, "query_reform_counts2")
```
```{r reform_eda2_wiki, fig.cap = query_reform_counts_cap2, dependson = c("reformulation", "reform_eda2")}
reform_times %>%
  group_by(wiki, `test group`) %>%
  do(count_reformulation(.$n_reformulate)) %>%
  ggplot(aes(x = `query reformulations`, y = proportion, fill = `test group`)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_brewer("Test Group", palette = "Set1", guide = guide_legend(ncol = 2)) +
  geom_text(aes(label = sprintf("%.1f%%", 100 * proportion), vjust = "bottom"),
            position = position_dodge(width = 1)) +
  labs(y = "Proportion of searches", x = "Approximate number of query reformulations per grouped search",
       title = "Number of query reformulations by test group and wiki",
       subtitle = "Queries were grouped when they shared common results or common key words") +
  theme(legend.position = "bottom")+
  facet_wrap(~ wiki, ncol = 3)
```

## Conclusion and Discussion

For the test group, we have a much better ZRR but slightly worse PaulScores, large decrease in clickthrough rate, and fewer users clicked on the first result first, which indicates that we are showing users worse results. However, dwell time and query reformulation analysis show that users may like the results they are getting on some dimension. We recommend deploying BM25 for all wikis but not reindex projects in space-less languages for now.

The relatively large decrease in engagement and relevancy for zhwiki may be the result of tokenizer behavior. Chinese is the sole language in this test where we do not have a custom analysis chain. We emit only unigrams, so any page that randomly has all the same characters as the query in it will be returned. 

The query reformulation analysis in this report is not ideal. On one hand, finding out shared tokens could not detect reformulated queries when users fix a typo in space-less languages. For example, when users modify their queries from "灯龙" to "灯笼" (lantern) they are fixing a typo, but tokenizers would take them as two different words. On the other hand, we found that many users like to try their queries in different languages. Without enabling search across wikis in different languages, we are unable to detect this kind of reformulation.
